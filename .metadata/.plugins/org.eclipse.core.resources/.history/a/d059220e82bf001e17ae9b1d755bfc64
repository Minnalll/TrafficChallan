package com.maveric.streambasics;

import org.apache.kafka.clients.consumer.Consumer;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.Topology;
import org.apache.kafka.streams.kstream.Consumed;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.Produced;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Collections;
import java.util.Properties;

// Serde Serializer-Deserializer
public class StreamDemo1 {
    private static final Logger Log = LoggerFactory.getLogger(StreamDemo1.class);

    public static void main(String[] args) throws Exception {

    	Properties props = KafkaPropertiesReader.read("application.properties");
		props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
		props.put(ConsumerConfig.GROUP_ID_CONFIG, "challan-consumer-group");
		props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
		props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
		System.out.println("After Config");
		// Create Kafka consumer
//		Consumer<String, String> consumer = new KafkaConsumer<>(props);
//		System.out.println("Props Config");
//		// Subscribe to the vehicleOverSpeed topic
//		consumer.subscribe(Collections.singletonList("vehicleOverSpeedTopic"));
//		System.out.println("Topic Subscription");

        Log.info("****properties" + props);
        StreamsBuilder builder = new StreamsBuilder();
        //source processor giving us stream from topic input-words
        KStream<String, String> inputStream = builder.stream("vehicleOverSpeedTopic", Consumed.with(Serdes.String(), Serdes.String()));

        KStream<String, String> upperStream = inputStream.peek((key, value) -> Log.info("key=" + key + "value=" + value))
                //intermediate map processor giving us new KStream<String,String> where key is string, value is message in uppercase
                .mapValues((value) -> value.toUpperCase())
                .peek((key, value) -> System.out.println("key=" + key + ",value=" + value));
        //sink processor sinking to topics upper-words
        upperStream.to("upper-words", Produced.with(Serdes.String(), Serdes.String()));


        //intermediate map processor giving us new KStream<String,Integer> where key is string, value is message length
        inputStream.mapValues(value -> value.length())
                .peek((key, value) -> System.out.println("key=" + key + ",value=" + value))
                //sink processor sinking to topic words-length
                .to("words-length", Produced.with(Serdes.String(), Serdes.Integer()));


        Topology topology = builder.build();
//        System.out.println("topology starts");
        Log.info("*****topology=" + topology.describe());
//        System.out.println("topology ends");
        try (KafkaStreams streams = new KafkaStreams(topology, props)) {
            streams.start();
            Thread.sleep(10000000);
        }


        Runtime.getRuntime().addShutdownHook(new Thread(() -> {
            Log.info("*** application closed");
        }));

    }

}
